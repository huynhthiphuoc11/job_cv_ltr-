{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Learning to Rank for Job–Resume Matching\n",
        "\n",
        "This notebook implements the **end-to-end experimental pipeline** described in the thesis section *Experimental Setup* for a Learning to Rank (LTR) system that recommends suitable candidates (resumes) for each job posting.\n",
        "\n",
        "Mục tiêu của notebook là cung cấp một pipeline **tái lập được** (reproducible) cho các bước:\n",
        "- Xây dựng và mô tả tập dữ liệu job postings thực tế và tập hồ sơ ứng viên synthetic.\n",
        "- Tiền xử lý và chuẩn hóa các trường dữ liệu chính (kỹ năng, kinh nghiệm, văn bản mô tả, vị trí địa lý).\n",
        "- Sinh tập cặp job–resume tiềm năng bằng chiến lược hai bước (lọc theo kỹ năng và vị trí, sau đó xếp hạng theo độ tương đồng ngữ nghĩa SBERT).\n",
        "- Thiết kế bộ đặc trưng cho bài toán Learning to Rank, bao phủ các khía cạnh skill matching, experience alignment, location matching và semantic similarity.\n",
        "- Xây dựng nhãn relevance bậc thang (0–3) dựa trên các ngưỡng định lượng, đảm bảo phân bố nhãn hợp lý cho huấn luyện.\n",
        "- Tổ chức dữ liệu theo chuẩn query–document (qid) cho các thuật toán LTR.\n",
        "- Huấn luyện mô hình LambdaMART và baseline rule-based, đánh giá theo NDCG@10, MAP@10, Precision@10 và kiểm định ý nghĩa thống kê (Wilcoxon signed-rank test).\n",
        "\n",
        "Toàn bộ cell được thiết kế theo thứ tự tuyến tính để có thể chạy từ trên xuống dưới trong môi trường Python 3.10 với các thư viện được nêu rõ, đảm bảo phù hợp để đính kèm như phần bổ sung kỹ thuật cho luận văn hoặc bài báo khoa học."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0. Setup: imports, configuration, and paths\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ndcg_score\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Optional: sentence-transformers for SBERT embeddings\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "except ImportError:\n",
        "    SentenceTransformer = None\n",
        "    print(\"sentence-transformers is not installed. Install it with `pip install sentence-transformers` if you want to run embedding steps.\")\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# Paths to data (adjust if your folder structure is different)\n",
        "DATA_DIR = \"../data\"\n",
        "JOB_PATH = os.path.join(DATA_DIR, \"jobs_vietnamworks_formatted_fixed.csv\")\n",
        "RESUME_PATH = os.path.join(DATA_DIR, \"synthetic_resumes.csv\")\n",
        "\n",
        "print(\"Job dataset:\", JOB_PATH)\n",
        "print(\"Resume dataset:\", RESUME_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Load and inspect datasets\n",
        "\n",
        "jobs = pd.read_csv(JOB_PATH)\n",
        "resumes = pd.read_csv(RESUME_PATH)\n",
        "\n",
        "print(\"Jobs shape:\", jobs.shape)\n",
        "print(\"Resumes shape:\", resumes.shape)\n",
        "\n",
        "display(jobs.head())\n",
        "display(resumes.head())\n",
        "\n",
        "jobs.info()\n",
        "resumes.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data preprocessing\n",
        "\n",
        "This section implements the *Cleaning and Normalization* and basic preparation for job–resume pairing:\n",
        "\n",
        "- Chuẩn hóa trường kỹ năng (`skills_list`, `Skills`, `Additional Skills`, `Certifications`, `Languages`)\n",
        "- Chuẩn hóa kinh nghiệm về số năm (`experience_years_min`, `experience_years_max`, `Years of Experience`)\n",
        "- Làm sạch các trường text dài (`description`, `Work Experience`, `Desired Job`)\n",
        "- Chuẩn hóa location về dạng tỉnh/thành để dùng cho matching theo vùng\n",
        "\n",
        "Các hàm dưới đây được thiết kế sao cho có thể tái sử dụng trong pipeline thực tế.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 Helper functions for cleaning and normalization\n",
        "\n",
        "VIETNAM_PROVINCES = [\n",
        "    \"Hồ Chí Minh\", \"Hà Nội\", \"Đà Nẵng\", \"Bình Dương\", \"Đồng Nai\", \"Bắc Ninh\", \"Bắc Giang\",\n",
        "    \"Hưng Yên\", \"Kiên Giang\", \"Hải Phòng\", \"Quảng Ninh\", \"Bến Tre\", \"Nam Định\"\n",
        "]\n",
        "\n",
        "SKILL_SYNONYMS = {\n",
        "    # Simple handcrafted ontology, có thể mở rộng thêm cho các nhóm kỹ năng chuyên ngành khác khi cần thiết\n",
        "    \"giao tiếp\": [\"giao tiếp\", \"communication\", \"communication skills\"],\n",
        "    \"quản lý thời gian\": [\"quản lý thời gian\", \"time management\"],\n",
        "    \"bán hàng\": [\"bán hàng\", \"sales\"],\n",
        "}\n",
        "\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # collapse whitespace\n",
        "    text = re.sub(r\"[\\r\\n\\t]\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def normalize_skills(raw: str) -> List[str]:\n",
        "    if pd.isna(raw):\n",
        "        return []\n",
        "    # Tách theo dấu phẩy hoặc dấu \"|\"\n",
        "    parts = re.split(r\"[,|]\", str(raw))\n",
        "    skills = []\n",
        "    for p in parts:\n",
        "        s = p.strip().lower()\n",
        "        if not s:\n",
        "            continue\n",
        "        skills.append(s)\n",
        "    # Ánh xạ synnonym về canonical key\n",
        "    normalized = []\n",
        "    for s in skills:\n",
        "        mapped = False\n",
        "        for canon, group in SKILL_SYNONYMS.items():\n",
        "            if s in [g.lower() for g in group]:\n",
        "                normalized.append(canon)\n",
        "                mapped = True\n",
        "                break\n",
        "        if not mapped:\n",
        "            normalized.append(s)\n",
        "    # Loại trùng lặp, giữ thứ tự\n",
        "    seen = set()\n",
        "    deduped = []\n",
        "    for s in normalized:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            deduped.append(s)\n",
        "    return deduped\n",
        "\n",
        "\n",
        "def normalize_location(raw: str) -> str:\n",
        "    if pd.isna(raw):\n",
        "        return \"\"\n",
        "    text = str(raw)\n",
        "    # Một số trường có dạng \"Hồ Chí Minh | Hà Nội | Đà Nẵng\"\n",
        "    parts = re.split(r\"[,|]\", text)\n",
        "    parts = [p.strip() for p in parts if p.strip()]\n",
        "    for p in parts:\n",
        "        for prov in VIETNAM_PROVINCES:\n",
        "            if prov.lower() in p.lower():\n",
        "                return prov\n",
        "    # Fallback: trả về phần đầu tiên đã clean\n",
        "    return parts[0] if parts else text.strip()\n",
        "\n",
        "\n",
        "def experience_years_from_range(min_years: float, max_years: float) -> float:\n",
        "    if pd.isna(min_years) and pd.isna(max_years):\n",
        "        return np.nan\n",
        "    if pd.isna(min_years):\n",
        "        return float(max_years)\n",
        "    if pd.isna(max_years):\n",
        "        return float(min_years)\n",
        "    return float((min_years + max_years) / 2.0)\n",
        "\n",
        "\n",
        "# Apply cleaning to jobs and resumes\n",
        "jobs[\"description_clean\"] = jobs[\"description\"].apply(clean_text)\n",
        "jobs[\"location_norm\"] = jobs[\"location_list\"].apply(normalize_location)\n",
        "jobs[\"skills_norm\"] = jobs[\"skills_list\"].apply(normalize_skills)\n",
        "\n",
        "jobs[\"experience_years\"] = jobs.apply(\n",
        "    lambda r: experience_years_from_range(r.get(\"experience_years_min\"), r.get(\"experience_years_max\")),\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "resumes[\"work_experience_clean\"] = resumes[\"Work Experience\"].apply(clean_text)\n",
        "resumes[\"desired_job_clean\"] = resumes[\"Desired Job\"].apply(clean_text)\n",
        "resumes[\"city_norm\"] = resumes[\"City\"].apply(normalize_location)\n",
        "resumes[\"skills_norm\"] = resumes[\"Skills\"].apply(normalize_skills)\n",
        "\n",
        "print(\"Preprocessing done.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. SBERT embeddings for jobs and resumes\n",
        "\n",
        "Ở phần này, chúng ta sinh embedding ngữ nghĩa cho job và resume để sử dụng cho:\n",
        "- Tìm kiếm gần đúng (top-N resume tiềm năng cho mỗi job)\n",
        "- Các đặc trưng semantic trong mô hình Learning to Rank.\n",
        "\n",
        "Nếu không cài `sentence-transformers`, bạn có thể bỏ qua cell này hoặc cài thêm thư viện để chạy đầy đủ pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 Build SBERT embeddings (optional but recommended)\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "\n",
        "if SentenceTransformer is not None:\n",
        "    sbert_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
        "\n",
        "    job_texts = (\n",
        "        jobs[\"title\"].fillna(\"\")\n",
        "        + \" \"\n",
        "        + jobs[\"description_clean\"].fillna(\"\")\n",
        "    ).tolist()\n",
        "\n",
        "    resume_texts = (\n",
        "        resumes[\"Desired Job\"].fillna(\"\")\n",
        "        + \" \"\n",
        "        + resumes[\"work_experience_clean\"].fillna(\"\")\n",
        "    ).tolist()\n",
        "\n",
        "    job_embs = sbert_model.encode(job_texts, batch_size=64, show_progress_bar=True, convert_to_numpy=True, normalize_embeddings=True)\n",
        "    resume_embs = sbert_model.encode(resume_texts, batch_size=64, show_progress_bar=True, convert_to_numpy=True, normalize_embeddings=True)\n",
        "\n",
        "    print(\"Job embeddings:\", job_embs.shape)\n",
        "    print(\"Resume embeddings:\", resume_embs.shape)\n",
        "else:\n",
        "    job_embs = None\n",
        "    resume_embs = None\n",
        "    print(\"SBERT not available; semantic similarity features will be limited.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Job–resume candidate generation\n",
        "\n",
        "Theo Experimental Setup, mỗi job chỉ ghép với **top-N = 200** resume tiềm năng để tránh bùng nổ tổ hợp:\n",
        "- Lọc sơ cấp theo **chồng lặp kỹ năng** và **vị trí địa lý**\n",
        "- Sau đó chọn top-N theo **cosine similarity** từ embedding SBERT (nếu có) hoặc fallback sang điểm kỹ năng.\n",
        "\n",
        "Để notebook vẫn chạy được trên máy hạn chế tài nguyên, có thể chọn subset job để demo (ví dụ 500 job đầu tiên).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 Candidate generation utility\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def skill_overlap_ratio(job_skills: List[str], res_skills: List[str]) -> float:\n",
        "    if not job_skills or not res_skills:\n",
        "        return 0.0\n",
        "    s_job = set(job_skills)\n",
        "    s_res = set(res_skills)\n",
        "    inter = len(s_job & s_res)\n",
        "    if len(s_job) == 0:\n",
        "        return 0.0\n",
        "    return inter / len(s_job)\n",
        "\n",
        "\n",
        "def build_candidate_pairs(\n",
        "    jobs_df: pd.DataFrame,\n",
        "    resumes_df: pd.DataFrame,\n",
        "    job_embs: np.ndarray | None,\n",
        "    resume_embs: np.ndarray | None,\n",
        "    top_n: int = 200,\n",
        "    min_skill_overlap: float = 0.3,\n",
        "    max_jobs: int | None = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Build job–resume candidate pairs as in Section 4.2.\n",
        "\n",
        "    Note: to keep runtime reasonable, you can set `max_jobs` to e.g. 500.\n",
        "    \"\"\"\n",
        "    if max_jobs is not None:\n",
        "        jobs_df = jobs_df.iloc[:max_jobs].copy()\n",
        "\n",
        "    pairs = []\n",
        "\n",
        "    for j_idx, j_row in tqdm(jobs_df.iterrows(), total=len(jobs_df)):\n",
        "        j_loc = j_row[\"location_norm\"]\n",
        "        j_skills = j_row[\"skills_norm\"] or []\n",
        "\n",
        "        # Filter resumes by same province (or any if missing)\n",
        "        if j_loc:\n",
        "            subset = resumes_df[resumes_df[\"city_norm\"] == j_loc]\n",
        "        else:\n",
        "            subset = resumes_df\n",
        "\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        # Compute skill overlap and keep those above threshold\n",
        "        overlaps = []\n",
        "        for r_idx, r_row in subset.iterrows():\n",
        "            r_skills = r_row[\"skills_norm\"] or []\n",
        "            ratio = skill_overlap_ratio(j_skills, r_skills)\n",
        "            if ratio >= min_skill_overlap:\n",
        "                overlaps.append((r_idx, ratio))\n",
        "\n",
        "        if not overlaps:\n",
        "            continue\n",
        "\n",
        "        # Sort by overlap descending as a first proxy\n",
        "        overlaps.sort(key=lambda x: x[1], reverse=True)\n",
        "        cand_indices = [idx for idx, _ in overlaps]\n",
        "\n",
        "        # If SBERT available, re-rank by cosine similarity\n",
        "        if job_embs is not None and resume_embs is not None:\n",
        "            j_vec = job_embs[j_idx]\n",
        "            r_vecs = resume_embs[cand_indices]\n",
        "            sims = np.dot(r_vecs, j_vec)\n",
        "            order = np.argsort(-sims)\n",
        "            ranked = [(cand_indices[i], overlaps[i][1], sims[i]) for i in order]\n",
        "        else:\n",
        "            ranked = [(idx, ratio, None) for idx, ratio in overlaps]\n",
        "\n",
        "        # Take top-N\n",
        "        ranked = ranked[:top_n]\n",
        "\n",
        "        for r_idx, ov, sim in ranked:\n",
        "            pairs.append(\n",
        "                {\n",
        "                    \"job_index\": j_idx,\n",
        "                    \"resume_index\": r_idx,\n",
        "                    \"skill_overlap\": ov,\n",
        "                    \"semantic_sim\": float(sim) if sim is not None else np.nan,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    pairs_df = pd.DataFrame(pairs)\n",
        "    print(\"Candidate pairs shape:\", pairs_df.shape)\n",
        "    return pairs_df\n",
        "\n",
        "\n",
        "candidate_pairs = build_candidate_pairs(\n",
        "    jobs_df=jobs,\n",
        "    resumes_df=resumes,\n",
        "    job_embs=job_embs,\n",
        "    resume_embs=resume_embs,\n",
        "    top_n=200,\n",
        "    min_skill_overlap=0.3,\n",
        "    # Có thể giới hạn số lượng job (ví dụ 500) nếu cần rút gọn để phù hợp tài nguyên tính toán\n",
        "    max_jobs=None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature engineering for Learning to Rank\n",
        "\n",
        "Ở bước này, ta xây dựng các đặc trưng chính như mô tả trong phần Experimental Setup:\n",
        "- **Skill Matching**: tỷ lệ kỹ năng trùng khớp\n",
        "- **Experience Alignment**: chênh lệch số năm kinh nghiệm\n",
        "- **Location & Preference**: match tỉnh/thành\n",
        "- **Semantic Features**: độ tương đồng job–resume (nếu có SBERT)\n",
        "\n",
        "Để notebook gọn và chạy được trên nhiều môi trường, ta hiện thực subset các đặc trưng cốt lõi, các đặc trưng mở rộng có thể bổ sung sau (title similarity, education matching, v.v.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1 Build feature matrix for candidate pairs\n",
        "\n",
        "\n",
        "def build_features(pairs_df: pd.DataFrame, jobs_df: pd.DataFrame, resumes_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    feat_rows = []\n",
        "\n",
        "    for _, row in pairs_df.iterrows():\n",
        "        j = jobs_df.loc[row[\"job_index\"]]\n",
        "        r = resumes_df.loc[row[\"resume_index\"]]\n",
        "\n",
        "        job_exp = j.get(\"experience_years\", np.nan)\n",
        "        res_exp = r.get(\"Years of Experience\", np.nan)\n",
        "        try:\n",
        "            res_exp = float(res_exp)\n",
        "        except Exception:\n",
        "            res_exp = np.nan\n",
        "\n",
        "        exp_gap = np.nan\n",
        "        if not pd.isna(job_exp) and not pd.isna(res_exp):\n",
        "            exp_gap = abs(job_exp - res_exp)\n",
        "\n",
        "        location_exact = 1.0 if j.get(\"location_norm\", \"\") == r.get(\"city_norm\", \"\") and j.get(\"location_norm\", \"\") != \"\" else 0.0\n",
        "\n",
        "        semantic = row.get(\"semantic_sim\", np.nan)\n",
        "\n",
        "        feat_rows.append(\n",
        "            {\n",
        "                \"job_index\": row[\"job_index\"],\n",
        "                \"resume_index\": row[\"resume_index\"],\n",
        "                \"skill_overlap\": row[\"skill_overlap\"],\n",
        "                \"exp_gap\": exp_gap if not pd.isna(exp_gap) else 0.0,\n",
        "                \"location_exact\": location_exact,\n",
        "                \"semantic_sim\": 0.0 if pd.isna(semantic) else float(semantic),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    feat_df = pd.DataFrame(feat_rows)\n",
        "\n",
        "    # Min–max normalization for numeric features\n",
        "    for col in [\"skill_overlap\", \"exp_gap\", \"semantic_sim\"]:\n",
        "        col_min = feat_df[col].min()\n",
        "        col_max = feat_df[col].max()\n",
        "        if col_max > col_min:\n",
        "            feat_df[col] = (feat_df[col] - col_min) / (col_max - col_min)\n",
        "        else:\n",
        "            feat_df[col] = 0.0\n",
        "\n",
        "    print(\"Feature matrix shape:\", feat_df.shape)\n",
        "    return feat_df\n",
        "\n",
        "\n",
        "features_df = build_features(candidate_pairs, jobs, resumes)\n",
        "features_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Relevance label construction\n",
        "\n",
        "Áp dụng schema gán nhãn 0–3 như mô tả trong Experimental Setup:\n",
        "- **3 – Rất phù hợp**: `skill_similarity ≥ 0.8`, `experience_gap ≤ 1 năm`, `title_similarity ≥ 0.8`\n",
        "- **2 – Phù hợp**: `skill_similarity ≥ 0.6`, `experience_gap ≤ 3 năm`\n",
        "- **1 – Ít phù hợp**: `skill_similarity ≥ 0.4` **hoặc** `title_similarity ≥ 0.5`\n",
        "- **0 – Không phù hợp**: còn lại.\n",
        "\n",
        "Trong notebook này, ta dùng `skill_overlap` (sau chuẩn hóa) và `exp_gap` (chuẩn hóa ngược lại) làm xấp xỉ, và giữ slot cho `title_similarity` để có thể mở rộng sau nếu cần.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.1 Labeling function\n",
        "\n",
        "\n",
        "def assign_relevance_labels(feat_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = feat_df.copy()\n",
        "\n",
        "    # Approximate title similarity placeholder (0.0) – có thể cập nhật sau\n",
        "    df[\"title_similarity\"] = 0.0\n",
        "\n",
        "    # Chuyển exp_gap đã chuẩn hóa về dạng \"fit\" (1 - gap_norm)\n",
        "    exp_fit = 1.0 - df[\"exp_gap\"]\n",
        "\n",
        "    labels = []\n",
        "    for _, row in df.iterrows():\n",
        "        skill_sim = row[\"skill_overlap\"]\n",
        "        title_sim = row[\"title_similarity\"]\n",
        "        exp_score = exp_fit.loc[row.name]\n",
        "\n",
        "        if skill_sim >= 0.8 and exp_score >= 0.8 and title_sim >= 0.8:\n",
        "            lbl = 3\n",
        "        elif skill_sim >= 0.6 and exp_score >= 0.6:\n",
        "            lbl = 2\n",
        "        elif skill_sim >= 0.4 or title_sim >= 0.5:\n",
        "            lbl = 1\n",
        "        else:\n",
        "            lbl = 0\n",
        "        labels.append(lbl)\n",
        "\n",
        "    df[\"label\"] = labels\n",
        "    print(\"Label distribution:\\n\", df[\"label\"].value_counts(normalize=True).sort_index())\n",
        "    return df\n",
        "\n",
        "\n",
        "labeled_df = assign_relevance_labels(features_df)\n",
        "labeled_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Query-based formatting for Learning to Rank\n",
        "\n",
        "Mỗi job được coi là một **query** (`qid`), mỗi resume là một **document** với nhãn relevance và vector đặc trưng:\n",
        "- `qid = job_index`\n",
        "- `label ∈ {0,1,2,3}`\n",
        "- `features = [skill_overlap, exp_gap, location_exact, semantic_sim, title_similarity]`\n",
        "\n",
        "Dữ liệu sau đó được tách train/validation/test theo **query** và chuyển thành format phù hợp cho LightGBM LambdaMART.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7.1 Build LTR dataset with groups\n",
        "\n",
        "ltr_df = labeled_df.copy()\n",
        "\n",
        "# Define qid as job_index\n",
        "ltr_df[\"qid\"] = ltr_df[\"job_index\"].astype(int)\n",
        "\n",
        "feature_cols = [\"skill_overlap\", \"exp_gap\", \"location_exact\", \"semantic_sim\", \"title_similarity\"]\n",
        "\n",
        "X = ltr_df[feature_cols].values\n",
        "y = ltr_df[\"label\"].values\n",
        "qids = ltr_df[\"qid\"].values\n",
        "\n",
        "# Group sizes for LightGBM\n",
        "unique_qids, group_sizes = np.unique(qids, return_counts=True)\n",
        "print(\"#queries:\", len(unique_qids), \" total pairs:\", len(ltr_df))\n",
        "\n",
        "# Train/val/test split at query level\n",
        "train_q, temp_q = train_test_split(unique_qids, test_size=0.30, random_state=RANDOM_SEED)\n",
        "val_q, test_q = train_test_split(temp_q, test_size=0.50, random_state=RANDOM_SEED)\n",
        "\n",
        "print(\"Train queries:\", len(train_q), \"Val queries:\", len(val_q), \"Test queries:\", len(test_q))\n",
        "\n",
        "\n",
        "def subset_by_qids(X, y, qids, target_qids):\n",
        "    mask = np.isin(qids, target_qids)\n",
        "    return X[mask], y[mask], qids[mask]\n",
        "\n",
        "\n",
        "X_train, y_train, q_train = subset_by_qids(X, y, qids, train_q)\n",
        "X_val, y_val, q_val = subset_by_qids(X, y, qids, val_q)\n",
        "X_test, y_test, q_test = subset_by_qids(X, y, qids, test_q)\n",
        "\n",
        "\n",
        "def group_from_qids(qids_array):\n",
        "    _, counts = np.unique(qids_array, return_counts=True)\n",
        "    return counts.tolist()\n",
        "\n",
        "\n",
        "group_train = group_from_qids(q_train)\n",
        "group_val = group_from_qids(q_val)\n",
        "group_test = group_from_qids(q_test)\n",
        "\n",
        "print(\"Train size:\", X_train.shape, \" Val size:\", X_val.shape, \" Test size:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training Learning to Rank models (LambdaMART)\n",
        "\n",
        "Ở bước này, ta huấn luyện mô hình **LambdaMART** với LightGBM như trong Experimental Setup:\n",
        "- `num_leaves = 63`, `max_depth = -1`, `learning_rate = 0.05`, `n_estimators = 300`, `min_child_samples = 50`\n",
        "- Sử dụng objective `lambdarank`, metric `ndcg`, group theo `qid`\n",
        "- Early stopping theo NDCG trên tập validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8.1 Train LambdaMART with LightGBM\n",
        "\n",
        "train_dataset = lgb.Dataset(X_train, label=y_train, group=group_train, feature_name=feature_cols)\n",
        "val_dataset = lgb.Dataset(X_val, label=y_val, group=group_val, feature_name=feature_cols, reference=train_dataset)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"lambdarank\",\n",
        "    \"metric\": \"ndcg\",\n",
        "    \"ndcg_at\": [10],\n",
        "    \"num_leaves\": 63,\n",
        "    \"max_depth\": -1,\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"n_estimators\": 300,\n",
        "    \"min_child_samples\": 50,\n",
        "    \"verbose\": -1,\n",
        "    \"seed\": RANDOM_SEED,\n",
        "}\n",
        "\n",
        "lgbm_model = lgb.train(\n",
        "    params,\n",
        "    train_dataset,\n",
        "    valid_sets=[train_dataset, val_dataset],\n",
        "    valid_names=[\"train\", \"val\"],\n",
        "    num_boost_round=300,\n",
        "    early_stopping_rounds=20,\n",
        "    verbose_eval=50,\n",
        ")\n",
        "\n",
        "print(\"Best iteration:\", lgbm_model.best_iteration)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Evaluation: NDCG@10, MAP@10, Precision@10 và baseline rule-based\n",
        "\n",
        "Ta đánh giá mô hình trên tập test ở mức query:\n",
        "- Tính NDCG@10, MAP@10, Precision@10\n",
        "- So sánh với baseline rule-based (dựa trên `skill_overlap`, `exp_gap`, `location_exact`)\n",
        "- Thực hiện Wilcoxon signed-rank test để kiểm định khác biệt ý nghĩa thống kê (p < 0.05).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9.1 Helper metrics and evaluation\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def precision_at_k(y_true, y_score, k=10):\n",
        "    order = np.argsort(-y_score)\n",
        "    topk = y_true[order][:k]\n",
        "    return np.mean(topk > 0) if len(topk) > 0 else 0.0\n",
        "\n",
        "\n",
        "def average_precision_at_k(y_true, y_score, k=10):\n",
        "    order = np.argsort(-y_score)\n",
        "    y_sorted = y_true[order][:k]\n",
        "    if not np.any(y_sorted > 0):\n",
        "        return 0.0\n",
        "    precisions = []\n",
        "    rel_count = 0\n",
        "    for i, rel in enumerate(y_sorted, start=1):\n",
        "        if rel > 0:\n",
        "            rel_count += 1\n",
        "            precisions.append(rel_count / i)\n",
        "    return float(np.mean(precisions)) if precisions else 0.0\n",
        "\n",
        "\n",
        "def evaluate_per_query(y_true, y_score, qids, k=10):\n",
        "    ndcgs, maps, precs = [], [], []\n",
        "    per_query_scores = {}\n",
        "\n",
        "    for q in np.unique(qids):\n",
        "        mask = qids == q\n",
        "        y_q = y_true[mask]\n",
        "        s_q = y_score[mask]\n",
        "\n",
        "        if len(y_q) == 0:\n",
        "            continue\n",
        "\n",
        "        # NDCG@k\n",
        "        ndcg = ndcg_score(y_true=[y_q], y_score=[s_q], k=k)\n",
        "        m_ap = average_precision_at_k(y_q, s_q, k=k)\n",
        "        p_at = precision_at_k(y_q, s_q, k=k)\n",
        "\n",
        "        ndcgs.append(ndcg)\n",
        "        maps.append(m_ap)\n",
        "        precs.append(p_at)\n",
        "\n",
        "        per_query_scores[q] = {\"ndcg\": ndcg, \"map\": m_ap, \"p@k\": p_at}\n",
        "\n",
        "    return {\n",
        "        \"ndcg@k\": float(np.mean(ndcgs)),\n",
        "        \"map@k\": float(np.mean(maps)),\n",
        "        \"p@k\": float(np.mean(precs)),\n",
        "        \"per_query\": per_query_scores,\n",
        "    }\n",
        "\n",
        "\n",
        "# Predict with LambdaMART\n",
        "pred_test_lgbm = lgbm_model.predict(X_test, num_iteration=lgbm_model.best_iteration)\n",
        "metrics_lgbm = evaluate_per_query(y_test, pred_test_lgbm, q_test, k=10)\n",
        "print(\"LambdaMART test metrics:\", metrics_lgbm[\"ndcg@k\"], metrics_lgbm[\"map@k\"], metrics_lgbm[\"p@k\"])\n",
        "\n",
        "\n",
        "# Simple rule-based baseline score\n",
        "rule_score_test = (\n",
        "    0.6 * X_test[:, feature_cols.index(\"skill_overlap\")] +\n",
        "    0.2 * (1.0 - X_test[:, feature_cols.index(\"exp_gap\")]) +\n",
        "    0.2 * X_test[:, feature_cols.index(\"location_exact\")]\n",
        ")\n",
        "\n",
        "metrics_rule = evaluate_per_query(y_test, rule_score_test, q_test, k=10)\n",
        "print(\"Rule-based test metrics:\", metrics_rule[\"ndcg@k\"], metrics_rule[\"map@k\"], metrics_rule[\"p@k\"])\n",
        "\n",
        "\n",
        "# Wilcoxon signed-rank test on per-query NDCG\n",
        "common_qids = sorted(set(metrics_lgbm[\"per_query\"].keys()) & set(metrics_rule[\"per_query\"].keys()))\n",
        "if common_qids:\n",
        "    ndcg_lgbm = [metrics_lgbm[\"per_query\"][q][\"ndcg\"] for q in common_qids]\n",
        "    ndcg_rule = [metrics_rule[\"per_query\"][q][\"ndcg\"] for q in common_qids]\n",
        "    stat, p_val = wilcoxon(ndcg_lgbm, ndcg_rule)\n",
        "    print(\"Wilcoxon signed-rank test on NDCG@10: stat=\", stat, \" p=\", p_val)\n",
        "else:\n",
        "    print(\"No common queries for Wilcoxon test.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
